# The Challenge of Black Box Governance for Private Citizens

"Black‑box governance” refers to governance arrangements in which the interactions, information flows and decision rules between public authorities and other actors that shape the implementation and enforcement of public policy and regulatory requirements are opaque to outsiders, even though they significantly affect public and compliance outcomes (Schmid, Meister, Klagge, & Seidl, 2020).

This audit addresses a core problem of democratic accountability: **asymmetric information**. Regulatory agencies possess complete knowledge of their internal processes, while the public sees only outputs. For COVID-19 vaccine safety monitoring, this creates a specific definitional crisis established by the TGA's own contradictory statements.

## **The Core Contradiction: Promise vs. Description**

The TGA committed to "enhanced safety monitoring" through its February 2021 Safety Plan, specifying 17 numbered strategies as conditions of provisional approval—the regulatory *quid pro quo* for accepting products with incomplete pre-market data.

But the TGA's Senate testimony (9 October 2025) described this enhanced monitoring as embedded in **"day-to-day processes"** with no distinct tracking or documentation system. This characterisation blurs the essential boundary: if enhanced monitoring is indistinguishable from routine operations, how can anyone verify it occurred?

The citizen's dilemma:
- Pharmacovigilance outputs were produced (150+ reports, 148 signals, 57 actions)
- Enhanced monitoring was promised (Safety Plan's 17 numbered strategies)
- But where's the line? Were routine activities actually enhanced? Or was enhanced monitoring simply routine operations relabelled?

From outside the agency, both scenarios produce identical outputs. Without clear boundaries and verification mechanisms, citizens cannot tell whether commitments were met.

## **The Evidentiary Pattern: A Snapshot from the Peak**

Consider this snapshot from the peak of the rollout: **October 2021**. While teaching future pharmacists about COVID-19 vaccine safety, TGA officials presented their monitoring framework. What they showed was their **routine system**. The promised differentiators—like AusVaxSafety integration and the 17 specific strategies—were absent. *(See [TGA teaching materials](./reference-documents/#tga-pharmacovigilance-teaching-materials-october-2021-evidence-of-a-gap-between-promise-and-practice))*

**This wasn't a public speech; it was technical training for professionals.** If the "enhanced" framework wasn't visible there, in detailed operational training, where was it?

This pattern combines with:
- FOI searches finding no dedicated Safety Plan tracking systems
- Senate testimony describing enhanced monitoring as "day-to-day processes"
- OAIC review documenting contradictory TGA statements
- Absence of integration evidence or audit trails in available records

**This pattern demands explanation.** You cannot definitively prove what it means, but the circumstantial evidence points toward the Safety Plan's enhanced monitoring not being implemented as a distinct, systematically tracked framework.

## **The Knowledge Problem**

Economist Friedrich Hayek identified that knowledge in complex systems is often **tacit and dispersed**—it cannot be fully articulated even by those who possess it. When regulatory agencies claim processes are "enhanced" but cannot document what makes them so, this creates Hayek's knowledge problem in reverse: knowledge that cannot be articulated cannot be verified.

This explains why the TGA might genuinely believe it conducted enhanced monitoring while being unable to demonstrate it externally. But it also reveals why such situations are democratically untenable: if enhanced monitoring cannot be distinguished from routine operations—even by the agency itself—the regulatory commitment becomes meaningless in practice.

## **The Lemon Market Problem**

Economist George Akerlof demonstrated how information asymmetry destroys markets through his "market for lemons" model. Buyers cannot verify quality, so they rationally assume the worst. Honest sellers exit, leaving only poor-quality goods.

In regulation, the same dynamic applies: Without proof that "enhanced" means something operationally distinct from "routine," the claim becomes unverifiable. Citizens cannot distinguish genuinely intensified surveillance from routine work relabelled. As with Akerlof's car market, scepticism becomes rational—not because of proven failure, but because verification is impossible.

Economist Joseph Stiglitz extended this analysis, showing that information problems require special institutional mechanisms to ensure accountability—mechanisms that become critical when citizens must verify regulatory promises they cannot directly observe.

## **The Practical Reality: Limited Powers, Limited Access**

This creates an acute problem for private citizens. We operate with:
- No compulsory process to require document production
- No discovery powers available to courts
- No section 155 powers to compel answers
- Limited statutory investigation tools
- Reliance primarily on voluntary FOI mechanisms
- Constrained funding for legal or expert support

Traditional audits examine known systems against defined standards with full access. Citizens face a different challenge: defining what to audit when regulators haven't clearly bounded the framework themselves, while possessing only limited authority to compel evidence.

## **The Epistemological Response: Working with Uncertainty**

Given these constraints, this audit employs two complementary forms of reasoning:

### **Deductive Reasoning: What Should Be Verifiable**
- Premise: Provisional approval requires enhanced monitoring
- Premise: Enhanced monitoring must be verifiable for accountability (Popper's falsifiability principle)
- Premise: TGA committed to specific enhanced outputs
- **Conclusion: Systematic implementation should be documentable**

The problem: This logical conclusion isn't supported by available evidence. The syllogism breaks down at the verification stage.

### **Abductive Reasoning: Inference to the Best Explanation**
When deduction fails, we employ abduction—looking at evidence patterns and inferring the most plausible explanation (Lipton, 2004).

The evidence pattern suggests several possible explanations:
1. Enhanced monitoring existed but wasn't documented
2. Enhanced monitoring existed in tacit, unarticulated form
3. Enhanced monitoring was routine operations meeting enhanced standards
4. Enhanced monitoring as a distinct framework wasn't systematically implemented

**Best explanation given available evidence: Option 4**—enhanced monitoring as a discrete, systematically implemented framework cannot be verified through records.

**Critical limitation:** Abduction produces probable explanations, not definitive proof. The finding is **absence of verifiable evidence**, not evidence of absence. This distinction is crucial in contexts of uncertainty, particularly in medical and regulatory settings where, as economist Kenneth Arrow demonstrated, information asymmetry creates unique verification challenges that require special institutional safeguards.

## **Methodological Commitments: Transparency as Accountability**

This methodology is designed to be transparent and correctable:

**Open access:** All primary sources linked, full analysis published, reasoning documented

**Version control:** Changes tracked with explanations, evolution of understanding visible

**Receptive to correction:** Actively seeking feedback, willing to revise findings

**Explicit limitations:** Clear about what citizen audits can and cannot determine

**Falsifiable claims:** Structured so evidence could prove findings wrong

**Nothing to hide:** Unlike agencies with tacit internal knowledge, this audit has nothing hidden. All reasoning, evidence, and limitations are visible.

This transparency creates its own accountability: if the analysis is flawed, the flaws are visible and challengeable. The goal is not to be definitively right but to demonstrate what can be verified from outside—and to show that verification gap matters.

## **The Trust Framework**

Philosopher Onora O'Neill established that institutions must **earn trust through verifiable evidence**, not demand it. The TGA's "enhanced monitoring" commitment was precisely such a ground for trust—a specific promise requiring demonstrable proof.

When that promise cannot be verified—when the line between routine and enhanced remains undefined and undocumented—the foundational bargain of provisional approval breaks down. Citizens cannot assess whether the regulatory *quid pro quo* was honoured.

O'Neill's framework applies to this audit itself: citizen oversight must earn trust through transparent methodology, acknowledged limitations, and openness to correction. The audit's credibility depends not on claiming certainty but on demonstrating rigorous, falsifiable analysis while embracing uncertainty.

## **Why This Matters: The Stakes for the Future**

This matters because the "black box" problem will recur. The next pandemic, the next fast-tracked therapy. This audit provides a methodology—and a demand.

**Public trust is not a blank cheque. It is a ledger.**

For every reduction in pre-market evidence (provisional approval), there must be a corresponding, **verifiable entry** of enhanced post-market scrutiny. The ledger for COVID-19 vaccines shows a promise on one side, and an unverifiable "day-to-day" process on the other.

This audit examines whether the TGA created the verifiable ground required for warranted public confidence. The issue is not vaccine safety outcomes but **regulatory integrity**:

- Can citizens verify that conditional approval commitments were met?
- Do regulatory promises require observable implementation evidence?
- Should enhanced monitoring be distinguishable from routine operations?
- What happens when verification is impossible?

For 68 million doses (94% of rollout) administered under provisional approval, these questions matter. The methodology here establishes a replicable standard for citizen oversight when regulatory boundaries remain undefined and evidentiary powers limited.

It demonstrates that democratic accountability requires not perfect knowledge but honest assessment of what can and cannot be verified from outside, combined with institutional structures that make verification possible.

---

## **References**

1. Akerlof, G.A.(1970). "The Market for 'Lemons': Quality Uncertainty and the Market Mechanism." *Quarterly Journal of Economics*, 84(3), 488–500.

2. Arrow, K.J. (1963). "Uncertainty and the Welfare Economics of Medical Care." *American Economic Review*, 53(5), 941–973.

3. Hayek, F.A. (1945). "The Use of Knowledge in Society." *American Economic Review*, 35(4), 519–530.

4. Lipton, P. (2004). *Inference to the Best Explanation* (2nd ed.). London: Routledge.

5. O'Neill, O. (2002). *A Question of Trust*. Cambridge: Cambridge University Press.

6. Popper, K.R. (2002). *The Logic of Scientific Discovery*. London: Routledge. (Original work published 1959.)

7. Schmid, B., Meister, T., Klagge, B., & Seidl, I. (2020). “Energy cooperatives and municipalities in local energy governance arrangements in Switzerland and Germany.” Journal of Environment & Development, 29(1), 26–53.

8. Stiglitz, J.E. (2002). "Information and the Change in the Paradigm in Economics." *American Economic Review*, 92(3), 460–501.



