name: Export Traffic with Daily Summary and Email

on:
  schedule:
    - cron: '0 21 * * *'
  workflow_dispatch:

jobs:
  export-traffic:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout traffic data repository
      uses: actions/checkout@v3
      with:
        repository: paulrekaris/TGA-Audit-Traffic-Data
        token: ${{ secrets.TRAFFIC_TOKEN }}
        path: traffic-repo
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install requests pandas
    
    - name: Export traffic data
      working-directory: traffic-repo
      env:
        TRAFFIC_TOKEN: ${{ secrets.TRAFFIC_TOKEN }}
      run: |
        cat > export.py << 'EXPORT_SCRIPT'
        import requests
        import json
        import os
        import pandas as pd
        from datetime import datetime, timezone

        GITHUB_TOKEN = os.environ['TRAFFIC_TOKEN']
        REPO_OWNER = 'paulrekaris'
        REPO_NAME = 'TGA-COVID19-Vaccine-Safety-Monitoring-Audit'
        BASE_URL = f'https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}'

        headers = {
            'Authorization': f'token {GITHUB_TOKEN}',
            'Accept': 'application/vnd.github.v3+json'
        }

        now = datetime.now(timezone.utc)
        date_str = now.strftime('%Y-%m-%d')

        print("Fetching traffic data...")
        clones_response = requests.get(f'{BASE_URL}/traffic/clones', headers=headers)
        views_response = requests.get(f'{BASE_URL}/traffic/views', headers=headers)
        referrers_response = requests.get(f'{BASE_URL}/traffic/popular/referrers', headers=headers)
        paths_response = requests.get(f'{BASE_URL}/traffic/popular/paths', headers=headers)

        clones_data = clones_response.json()
        views_data = views_response.json()
        referrers_data = referrers_response.json()
        paths_data = paths_response.json()

        try:
            clones_df = pd.read_csv('clones.csv')
            views_df = pd.read_csv('views.csv')
        except FileNotFoundError:
            clones_df = pd.DataFrame(columns=['date', 'total_clones', 'unique_cloners'])
            views_df = pd.DataFrame(columns=['date', 'total_views', 'unique_visitors'])

        today_clones_total = clones_data.get('count', 0)
        today_clones_unique = clones_data.get('uniques', 0)
        today_views_total = views_data.get('count', 0)
        today_views_unique = views_data.get('uniques', 0)

        if date_str in clones_df['date'].values:
            print(f"Data for {date_str} already exists. Exiting to prevent duplicates.")
            exit(0)

        yesterday_clones = 0
        yesterday_unique_cloners = 0
        yesterday_views = 0
        yesterday_unique_visitors = 0

        if len(clones_df) > 0:
            if 'clones' in clones_data and len(clones_data['clones']) > 0:
                newest_day = clones_data['clones'][-1]
                yesterday_clones = newest_day.get('count', 0)
                yesterday_unique_cloners = newest_day.get('uniques', 0)

        if len(views_df) > 0:
            if 'views' in views_data and len(views_data['views']) > 0:
                newest_day = views_data['views'][-1]
                yesterday_views = newest_day.get('count', 0)
                yesterday_unique_visitors = newest_day.get('uniques', 0)

        new_clones_row = pd.DataFrame([{
            'date': date_str,
            'total_clones': today_clones_total,
            'unique_cloners': today_clones_unique
        }])
        new_views_row = pd.DataFrame([{
            'date': date_str,
            'total_views': today_views_total,
            'unique_visitors': today_views_unique
        }])

        clones_df = pd.concat([clones_df, new_clones_row], ignore_index=True)
        views_df = pd.concat([views_df, new_views_row], ignore_index=True)

        clones_df.to_csv('clones.csv', index=False)
        views_df.to_csv('views.csv', index=False)

        if len(clones_df) >= 7:
            avg_7day_clones = clones_df.tail(7)['total_clones'].diff().mean()
            avg_7day_unique = clones_df.tail(7)['unique_cloners'].diff().mean()
        else:
            avg_7day_clones = clones_df['total_clones'].mean() if len(clones_df) > 0 else 0
            avg_7day_unique = clones_df['unique_cloners'].mean() if len(clones_df) > 0 else 0

        days_tracked = len(clones_df)
        total_clones_alltime = clones_df['total_clones'].iloc[-1] if len(clones_df) > 0 else 0
        avg_daily_clones = total_clones_alltime / days_tracked if days_tracked > 0 else 0

        referrers_text = ""
        if referrers_data and len(referrers_data) > 0:
            for i, ref in enumerate(referrers_data[:4], 1):
                referrers_text += f"   {i}. {ref['referrer']} ({ref['count']} views)\n"
        else:
            referrers_text = "   No external referrers in past 14 days\n"

        paths_text = ""
        if paths_data and len(paths_data) > 0:
            for i, path in enumerate(paths_data[:4], 1):
                path_title = path['path'] if path['path'] != '/' else 'Main page'
                paths_text += f"   {i}. {path_title} ({path['count']} views)\n"
        else:
            paths_text = "   No path data available\n"

       summary = f"""
________________________________________________________________
TGA AUDIT TRAFFIC SUMMARY
{now.strftime('%A, %d %B %Y')}
________________________________________________________________

ðŸ“Š YESTERDAY'S ACTIVITY
   {yesterday_clones} clones ({yesterday_unique_cloners} unique)
   {yesterday_views} views ({yesterday_unique_visitors} unique visitors)

ðŸ“ˆ TRENDS (7-day average)
   Daily clones: {avg_7day_clones:.1f}
   Daily unique cloners: {avg_7day_unique:.1f}

ðŸ”— TOP TRAFFIC SOURCES
{referrers_text}
ðŸ“„ MOST VIEWED CONTENT
{paths_text}
________________________________________________________________

14-DAY WINDOW (Rolling)
   Total clones: {today_clones_total:,} | Unique: {today_clones_unique}
   Total views: {today_views_total:,} | Unique: {today_views_unique}
   Note: Window shifts daily - represents last 14 days

All-Time Stats (since tracking began)
   Days tracked: {days_tracked}
   Total clones recorded: {total_clones_alltime:,}
   Average daily clones: {avg_daily_clones:.1f}

________________________________________________________________
Manual checks:
Referring sites: https://github.com/{REPO_OWNER}/{REPO_NAME}/graphs/traffic
Full data: https://github.com/paulrekaris/TGA-Audit-Traffic-Data
"""

        with open('LATEST_SUMMARY.txt', 'w') as f:
            f.write(summary)

        os.makedirs('daily-summaries', exist_ok=True)
        with open(f'daily-summaries/summary_{date_str}.txt', 'w') as f:
            f.write(summary)

        os.makedirs('json-backups', exist_ok=True)
        with open(f'json-backups/clones_{date_str}.json', 'w') as f:
            json.dump(clones_data, f, indent=2)
        with open(f'json-backups/views_{date_str}.json', 'w') as f:
            json.dump(views_data, f, indent=2)

        print("Traffic data exported successfully!")
        print(summary)
        EXPORT_SCRIPT
        python export.py
    
    - name: Commit and push changes
      working-directory: traffic-repo
      run: |
        git config user.name "GitHub Action"
        git config user.email "action@github.com"
        git add .
        git commit -m "Traffic data and summary for $(date +%Y-%m-%d)" || echo "No changes to commit"
        git push
    
    - name: Send email with summary
      uses: dawidd6/action-send-mail@v3
      with:
        server_address: smtp.gmail.com
        server_port: 587
        username: ${{ secrets.EMAIL_USERNAME }}
        password: ${{ secrets.EMAIL_PASSWORD }}
        subject: TGA Audit Traffic Summary - ${{ github.event.repository.updated_at }}
        to: prekas23@gmail.com
        from: GitHub Traffic Monitor <prekas23@gmail.com>
        body: file://traffic-repo/LATEST_SUMMARY.txt
